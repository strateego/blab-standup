# 2 Oct 2018
# or, Backups to the Hutch's economy storage

The Hutch provides each group, at no additional cost, 5TB of "economy" object
storage using OpenStack Swift (an S3-like data store).  Documentation for it is
inconsistent, sometimes incorrect, and pretty scattered, but [the SciComp wiki
page about it][economy] is the best place to start.  Make sure to follow links
to further documentation from that page.  Center IT provides an [brief
summary][summary] of how Economy storage fits into the other storage offerings
at the Hutch.

[economy]: https://teams.fhcrc.org/sites/citwiki/SciComp/Pages/How%20to%20use%20Economy%20File%20Storage.aspx
[summary]: https://centernet.fredhutch.org/cn/u/center-it/services/storedataprotect.html


## First, fix DNS resolution if it doesn't work.

I found that many network tools, like `ping`, were unable to lookup
`tin.fhcrc.org`, the name used by economy storage.  DNS tools like `dig` and
`host` did fine.  My guess from packet captures and strace logs is this is due
to either the large number of `A` records causing oversized UDP responses
(which not all clients deal with).

I had to add this bit to my `/etc/hosts`:

    # DNS for tin.fhcrc.org (and its CNAME s3.fhcrc.org) is busted, I think due to
    # the oversized UDP response (or maybe due to the AAAA query s3 CNAME response
    # without AAAA records for tin.fhcrc.org).
    140.107.116.220 tin.fhcrc.org s3.fhcrc.org


## Déjà Dup

After much trial and error, I was able to setup [Déjà Dup][] on Ubuntu to
backup to this storage service.  Behind the scenes, Déjà Dup uses
[duplicity][], a well-regarded Unix backup tool.

[Déjà Dup]: https://wiki.gnome.org/Apps/DejaDup
[duplicity]: http://duplicity.nongnu.org

In later versions, many [previously-supported remote storage providers were
hidden][clouds].  They are not slated to be removed though, and so can be
re-enabled manually.  Switch to OpenStack Swift by running:

    dconf write /org/gnome/deja-dup/backend "'openstack'"

[clouds]: https://wiki.gnome.org/Apps/DejaDup/Clouds

Then start the app and configure the storage location.

**Username:** `Swift_bedford_t`
**Container:** some name of your choosing, I used `tsibley-backup-whunk` (whunk is my machine name)
**Auth URL:** `https://tin.fhcrc.org/auth/v1.0`
**Tenant name:** leave blank

Start a backup, and when logging in, use the value of the `password` field in
the JSON document you can acquire at <https://toolbox.fhcrc.org/sw2srv/swift/account>.

While the app appears to support v2 auth with your normal username and password
(and filling in tenant), it apparently doesn't work because of an
incompatibility with the server.


## CLI

You can verify your backups manually or use economy storage for other things
using CLI tools.

The Hutch offers `swc`, Swift commander, in the Python package
`swift-commander`.  You can also use the lower-level `swift` command provided
by the `python-swiftclient` package on PyPi.

You can auth two different ways, described below.  I like making envdirs for
these.  Note that the backups above are using v1 auth.

## v1 auth

    export ST_AUTH=https://tin.fhcrc.org/auth/v1.0
    export ST_USER=Swift_bedford_t
    export ST_KEY=...

The "key" is the value of the `password` field in the JSON document you can
acquire at <https://toolbox.fhcrc.org/sw2srv/swift/account>.

I discovered accidentally that v1 auth will also let you login with your own
Hutch username and password instead of using the group-based password.  The
provided storage area is separate from the group-based storage area.

This isn't documented anywhere by the Hutch and I suspect it isn't intended to
be used.  I certainly don't want to be billed for usage!

## v2 auth

    export OS_AUTH_URL=https://tin.fhcrc.org/auth/v2.0
    export OS_TENANT_NAME=AUTH_Swift_bedford_t
    export OS_USERNAME=tsibley
    export OS_PASSWORD=...

Password is your Fred Hutch password.
